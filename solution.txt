Итоговое решение - ансамбль разных подходов:
1. предсказание трека языковой моделью. Выбор пал на трансформер декодер. Усреднил несколько моделей: одна учитывает только последовательность треков, другая - треков и артистов (просто складывал эмбеддинги трека и артиста). Так как треков очень много, при обучении фитил распределение не по всем трекам, а по k кандидатам, среди которых один положительный. Логиты треков получались с помощью матричного умножения логитов модели на k элементов из матрицы эмбеддингов.
2. предсказание артиста языковой моделью. Тоже трансформер декодер.
3. вариант коллаборативной фильтрации: для тестового юзера ищем топ-m похожих юзеров из треина в смысле bm25 на последовательностях треков -> берём все треки этих юзеров, выкинув те, что тестовый юзер уже лайкнул -> для каждого трека аггрегируем скор: score(track) = sum(bm25(user) / rank(user) for user in users) + log(frequency(track)), где users - отранжированный по bm25 список юзеров, прослушавших трек, bm25(user) - bm25 скор юзера, rank(user) - место юзера в топ-m, frequency(track) - сколько юзеров треина лайкнули трек -> берём топ-1000 по этому скору. Поиск реализовал с помощью elasticsearch.
4. p(track|history) = p(track|artist, history) * p(artist|history). Первая вероятность оценивается частотно, вторая - с помощью модели из п.2.
5. бейзлайн со следующими доработками: топ-1000 -> топ-50000; взвешивать скоры треков с весами: вес трека тем выше, чем ближе трек к концу истории. Реализовал через произведение спарс матриц (scipy.sparse.csr_matrix).